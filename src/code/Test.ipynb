{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\Vinay\\Code\\NN\")   # make lib.py importable\n",
    "from lib import draw_dot, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing MLP on test data\n",
    "xs = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # desired targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = MLP(3, [4,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00024105967734444324\n",
      "1 0.00024097196702897147\n",
      "2 0.00024088431987881196\n",
      "3 0.00024079673582601626\n",
      "4 0.00024070921480277065\n",
      "5 0.0002406217567413405\n",
      "6 0.00024053436157409392\n",
      "7 0.0002404470292334951\n",
      "8 0.0002403597596521021\n",
      "9 0.0002402725527625679\n",
      "10 0.00024018540849765163\n",
      "11 0.00024009832679019593\n",
      "12 0.00024001130757314676\n",
      "13 0.00023992435077954335\n",
      "14 0.0002398374563425199\n",
      "15 0.00023975062419530672\n",
      "16 0.0002396638542712251\n",
      "17 0.00023957714650370504\n",
      "18 0.00023949050082624823\n",
      "19 0.00023940391717247443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(20):\n",
    "    #forward pass\n",
    "    pred=[NN(x) for x in xs]\n",
    "    #calculate loss\n",
    "    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, pred))\n",
    "    \n",
    "    #backward pass\n",
    "    for p in NN.parameters():\n",
    "        p.grad = 0 #changing all grad to 0 to avoid abrupt changes due to accumulation of grads\n",
    "    loss.backward()\n",
    "    \n",
    "    #Change weights a little\n",
    "    for p in NN.parameters():\n",
    "        p.data += -0.05*p.grad  \n",
    "\n",
    "    print(i, loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.9932110183172067),\n",
       " Value(data=-0.994666909828953),\n",
       " Value(data=-0.9906767965907026),\n",
       " Value(data=0.9911710888383947)]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TestNN(3,[441]).png'"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=draw_dot(loss)\n",
    "a.render('TestNN(3,[441])', format='png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
